--
-- PXF HDFS extended regression suite
--
-- Prerequisites:
--
--   Must have a running hdfs with REST service on port 50070
--   Must have HADOOP_ROOT, HBASE_ROOT, HIVE_ROOT and ZOOKEEPER_ROOT set.
--
-- TODO: test gpdbwritable write/read when it is enabled.
-- TODO: test PB, AVRO, THRIFT when it is enabled (read only, with pre formatted files).
-- TODO: test protocol validator for pxf once written.
-- TODO: test parameter passing, filter passing

--------------------------------------------------------------------------------
-- GPHDFS
--------------------------------------------------------------------------------
--
-- Load HDFS with test data
--
\! ${HADOOP_ROOT}/bin/hadoop fs -mkdir /gpdb_regression_data
\! ${HADOOP_ROOT}/bin/hadoop fs -copyFromLocal @abs_srcdir@/data/pxf/writable_inside_sequence1.tbl /gpdb_regression_data/writable_inside_sequence1.tbl
\! sh @abs_srcdir@/helpers/create_table_file.sh @abs_srcdir@/data/pxf/multiblock.tbl
\! ${HADOOP_ROOT}/bin/hadoop fs -copyFromLocal @abs_srcdir@/data/pxf/multiblock.tbl /gpdb_regression_data/multiblock.tbl

--
-- Test multiblock file
--
CREATE EXTERNAL TABLE mbt(t1 text,
                          a1 integer)
LOCATION ('pxf://@hostname@:50070/gpdb_regression_data/multiblock.tbl?FRAGMENTER=HdfsDataFragmenter&ACCESSOR=TextFileAccessor&RESOLVER=TextResolver')
FORMAT 'TEXT' (DELIMITER ',');
SELECT t1, a1 FROM mbt ORDER BY t1 LIMIT 10;
SELECT SUM(a1) from mbt;
SELECT COUNT(*) FROM mbt;
SELECT cnt < 32768000 AS check FROM (SELECT COUNT(*) AS cnt FROM mbt WHERE gp_segment_id = 0) AS a;
DROP EXTERNAL TABLE mbt;
--
-- Test extensibility
--
CREATE EXTERNAL TABLE extens(tmp1  timestamp, 
                            num1  integer, 
                            num2  integer, 
                            num3  integer, 
                            num4  integer,
                            t1    text, 
                            t2    text, 
                            t3    text, 
                            t4    text, 
                            t5    text, 
                            t6    text, 
                            dub1  double precision, 
                            dub2  double precision, 
                            dub3  double precision, 
                            ft1   real, 
                            ft2   real, 
                            ft3   real, 
                            ln1   bigint, 
                            ln2   bigint, 
                            ln3   bigint, 
                            bt    bytea)
LOCATION ('pxf://@hostname@:50070/gpdb_regression_data/writable_inside_sequence1.tbl?FRAGMENTER=TestHdfsDataFragmenter&ACCESSOR=TestSequenceFileAccessor&RESOLVER=TestWritableResolver&DATA-SCHEMA=CustomWritable&ANALYZER=TestHdfsAnalyzer')
FORMAT 'custom' (formatter='pxfwritable_import');
SELECT num1, t1, t2, t3 FROM extens ORDER BY num1;
ANALYZE extens;
DROP EXTERNAL TABLE extens;
--
-- Cleanup: delete all data that was copied into hdfs
--
-- start_ignore
\! ${HADOOP_ROOT}/bin/hadoop fs -rm -r /gpdb_regression_data
\! rm @abs_srcdir@/data/pxf/multiblock.tbl
-- end_ignore
