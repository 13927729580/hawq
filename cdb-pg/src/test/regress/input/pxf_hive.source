--
-- PXF HIVE regression suite 
--
-- Prerequisites:
--
--   Must have a running hdfs with REST service on port 50070
--   Must have a running YARN services (to load data into Hive).
--   Must have HADOOP_ROOT, HBASE_ROOT, HIVE_ROOT and ZOOKEEPER_ROOT set.
--   Must have Hive Thrift server running locally on port 10000
--
-- TODO: test gpdbwritable write/read when it is enabled.
-- TODO: test PB, AVRO, THRIFT when it is enabled (read only, with pre formatted files).
-- TODO: test protocol validator for pxf once written.
-- TODO: test parameter passing, filter passing

-- start_matchsubs
--                                                                                               
-- # create a match/subs expression to handle ip addresses that change
--
-- m/(ERROR|WARNING):.*remote component error.*\(\d+\).*from.*'\d+\.\d+\.\d+\.\d+:\d+'.*/
-- s/'\d+\.\d+\.\d+\.\d+:\d+'/'SOME_IP:SOME_PORT'/
--
-- end_matchsubs

--------------------------------------------------------------------------------
-- HIVE
--------------------------------------------------------------------------------
--
-- 0. Compiling the HiveThinClient
\! javac -cp `${HADOOP_ROOT}/bin/hadoop classpath` @abs_srcdir@/helpers/HiveThinClient.java

-- 1. Hive table stored as text
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "create table reg_txt (s1 string,s2 string,n1 int, d1 double)row format delimited fields terminated by ','"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "load data local inpath '@abs_srcdir@/data/pxf/hive_small_data.txt' into table reg_txt"

CREATE EXTERNAL TABLE hv_txt(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision)
LOCATION ('pxf://@hostname@:50070/reg_txt?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_txt order by t1;

-- 2. Hive table stored as sequence
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "create table reg_seq (t0 string, t1 string, num1 int, d1 double) row format delimited fields terminated by ',' STORED AS SEQUENCEFILE"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "insert into table reg_seq select * from reg_txt"

CREATE EXTERNAL TABLE hv_seq(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision)
LOCATION ('pxf://@hostname@:50070/reg_seq?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_seq order by t1;

-- 3. Hive table stored as rcfile
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "create table reg_rc (t0 string, t1 string, num1 int, d1 double) STORED AS RCFILE"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "insert into table reg_rc select * from reg_txt"

CREATE EXTERNAL TABLE hv_rc(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision)
LOCATION ('pxf://@hostname@:50070/reg_rc?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_rc order by t1;

-- 4. Hive table stored in several partitions where each partition is stored in a diferrent format
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "create external table reg_heterogen (s1 string,s2 string,n1 int, d1 double) partitioned by (fmt string)  row format delimited fields terminated by ','"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "alter table reg_heterogen add partition (fmt = 'txt') location 'hdfs:/hive/warehouse/reg_txt'"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "alter table reg_heterogen add partition (fmt = 'rc') location 'hdfs:/hive/warehouse/reg_rc'"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "alter table reg_heterogen add partition (fmt = 'seq') location 'hdfs:/hive/warehouse/reg_seq'"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "alter table reg_heterogen partition (fmt='rc') set fileformat RCFILE"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "alter table reg_heterogen partition (fmt='seq') set fileformat SEQUENCEFILE"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "show partitions reg_heterogen"

CREATE EXTERNAL TABLE hv_heterogen(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision,
t3 text)
LOCATION ('pxf://@hostname@:50070/reg_heterogen?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_heterogen order by t3, t1;

-- Test analyze for Hive table.
ANALYZE hv_heterogen;
select relpages, reltuples from pg_class where relname = 'hv_heterogen';

-- 5. Hive table with collection types (non primitive types)
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "CREATE TABLE reg_collections ( s1 STRING, f1 FLOAT, a1 ARRAY<STRING> , m1 MAP<STRING,  FLOAT > , sr1 STRUCT<street:STRING,  city:STRING,  state:STRING,  zip:INT > )  ROW FORMAT DELIMITED  FIELDS TERMINATED BY '\001' COLLECTION ITEMS TERMINATED BY '\002' MAP KEYS TERMINATED BY '\003'  LINES TERMINATED BY '\n'  STORED AS TEXTFILE"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "load data local inpath '@abs_srcdir@/data/pxf/hive_collections.txt' into table reg_collections"

CREATE EXTERNAL TABLE hv_collections(
t1    text,   
f1    real,
t2    text, 
t3    text, 
t4    text,
t5    text, 
f2    real,
t6    text,
f3    real,
t7    text,
t8    text,
t9    text,
num1  integer)
LOCATION ('pxf://@hostname@:50070/reg_collections?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_collections order by t1;

-- 6. View - negative test
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "create view reg_txt_view as select s1 from reg_txt"

CREATE EXTERNAL TABLE hv_view(
t1    text)
LOCATION ('pxf://@hostname@:50070/reg_txt_view?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_view order by t1;

-- 7. Clean after Hive
drop external table hv_view;
drop external table hv_collections;
drop external table hv_heterogen;
drop external table hv_rc;
drop external table hv_seq;
drop external table hv_txt;

\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "drop view reg_txt_view"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "drop table reg_collections"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "drop table reg_heterogen"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "drop table reg_rc"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "drop table reg_seq"
\! java -cp `${HADOOP_ROOT}/bin/hadoop classpath`:@abs_srcdir@/helpers HiveThinClient "drop table reg_txt"
